{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# If you want to access the version you have already modified, click \"Edit\"\n# If you want to access the original sample code, click \"...\", then click \"Copy & Edit Notebook\"","metadata":{}},{"cell_type":"code","source":"## This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":19.351342,"end_time":"2022-02-23T10:03:06.247288","exception":false,"start_time":"2022-02-23T10:02:46.895946","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:22.510394Z","iopub.execute_input":"2022-03-20T08:16:22.511008Z","iopub.status.idle":"2022-03-20T08:16:22.515227Z","shell.execute_reply.started":"2022-03-20T08:16:22.510968Z","shell.execute_reply":"2022-03-20T08:16:22.514021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random\nfrom torch.cuda import amp\nfrom pathlib import Path\nimport pandas as pd","metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:22.516476Z","iopub.execute_input":"2022-03-20T08:16:22.516863Z","iopub.status.idle":"2022-03-20T08:16:24.034413Z","shell.execute_reply.started":"2022-03-20T08:16:22.516825Z","shell.execute_reply":"2022-03-20T08:16:24.03327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:24.037695Z","iopub.execute_input":"2022-03-20T08:16:24.038069Z","iopub.status.idle":"2022-03-20T08:16:24.048441Z","shell.execute_reply.started":"2022-03-20T08:16:24.038018Z","shell.execute_reply":"2022-03-20T08:16:24.047482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Transforms**\nTorchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n\nPlease refer to PyTorch official website for details about different transforms.","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n])\n\n# However, it is also possible to use augmentation in the testing phase.\n# You may use train_tfm to produce a variety of images and then test using ensemble methods\ntrain_tfm = transforms.Compose([\n    transforms.Resize((448, 448)),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.5),\n    transforms.RandomHorizontalFlip(p=0.3),\n    transforms.RandomVerticalFlip(p=0.3),\n    transforms.RandomAffine(degrees=10, translate=(0.3, 0.3), scale=(0.5, 1.5), shear=10),\n    transforms.RandomCrop(256),\n    transforms.ToTensor(),\n])\n","metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:24.050092Z","iopub.execute_input":"2022-03-20T08:16:24.050991Z","iopub.status.idle":"2022-03-20T08:16:24.060004Z","shell.execute_reply.started":"2022-03-20T08:16:24.050927Z","shell.execute_reply":"2022-03-20T08:16:24.059195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Datasets**\nThe data is labelled by the name, so we load images and label while calling '__getitem__'","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class FoodDataset(Dataset):\n\n    def __init__(self,path,tfm=test_tfm,files = None):\n        super(FoodDataset).__init__()\n        self.path = path\n        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n        print(f\"One {path} sample\",self.files[0])\n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        #im = self.data[idx]\n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n        return im,label\n","metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:24.063124Z","iopub.execute_input":"2022-03-20T08:16:24.063459Z","iopub.status.idle":"2022-03-20T08:16:24.079724Z","shell.execute_reply.started":"2022-03-20T08:16:24.063427Z","shell.execute_reply":"2022-03-20T08:16:24.078785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class Bottleneck(nn.Module):\n    expansion = 4\n \n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n \n    def forward(self, x):\n        residual = x\n \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n \n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n \n        out = self.conv3(out)\n        out = self.bn3(out)\n \n        if self.downsample is not None:\n            residual = self.downsample(x)\n \n        out += residual\n        out = self.relu(out)\n \n        return out\n\n\nclass ResNet(nn.Module):\n \n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)  # /2\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)  # /2\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)  # /2\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)  # /2\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)  # /2\n        self.avgpool = nn.AvgPool2d(8, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n \n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n \n        return nn.Sequential(*layers)\n \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n \n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n \n        return x\n\n\ndef resnet18(pretrained=False, num_classes=11):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [2, 2, 2, 2], num_classes)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:16:24.081892Z","iopub.execute_input":"2022-03-20T08:16:24.082217Z","iopub.status.idle":"2022-03-20T08:16:24.113207Z","shell.execute_reply.started":"2022-03-20T08:16:24.082172Z","shell.execute_reply":"2022-03-20T08:16:24.112319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataloader","metadata":{}},{"cell_type":"code","source":"batch_size = 128\n_dataset_dir = \"../input/ml2022spring-hw3b/food11\"\n# Construct datasets.\n# The argument \"loader\" tells how torchvision reads the data.\ntrain_set = FoodDataset(os.path.join(_dataset_dir,\"training\"), tfm=train_tfm)\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)\nvalid_set = FoodDataset(os.path.join(_dataset_dir,\"validation\"), tfm=test_tfm)\nvalid_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0, pin_memory=True)","metadata":{"papermill":{"duration":0.054295,"end_time":"2022-02-23T10:03:08.266338","exception":false,"start_time":"2022-02-23T10:03:08.212043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:24.114575Z","iopub.execute_input":"2022-03-20T08:16:24.11492Z","iopub.status.idle":"2022-03-20T08:16:24.176022Z","shell.execute_reply.started":"2022-03-20T08:16:24.114876Z","shell.execute_reply":"2022-03-20T08:16:24.17478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## EMA","metadata":{}},{"cell_type":"code","source":"from copy import deepcopy\nimport numpy as np\n\n\nclass ExponentialMovingAverageModel:\n    \"\"\"\n    从始至终维持一个model，并不断更新该model的参数，但该mdoel仅仅是为了inference。\n    随着训练的进行，越靠后面的模型参数对ema模型的影响越大。\n    \"\"\"\n    def __init__(self, model, decay_ratio=0.9999, tot_epoch=200, update_num=0):\n        self.ema = deepcopy(model).eval()\n        self.update_num = update_num\n        self.get_decay_weight = lambda x: decay_ratio * (1 - np.exp(-x / tot_epoch))\n        for parm in self.ema.parameters():\n            parm.requires_grad_(False)\n\n    def update(self, model):\n        with torch.no_grad():\n            self.update_num += 1\n            decay_weight = self.get_decay_weight(self.update_num)\n            cur_state_dict = model.state_dict()\n            for k, v in self.ema.state_dict().items():\n                if v.dtype.is_floating_point:\n                    v *= decay_weight\n                    v += (1 - decay_weight) * cur_state_dict[k].detach()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:16:24.177263Z","iopub.execute_input":"2022-03-20T08:16:24.177534Z","iopub.status.idle":"2022-03-20T08:16:24.187075Z","shell.execute_reply.started":"2022-03-20T08:16:24.177473Z","shell.execute_reply":"2022-03-20T08:16:24.186397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = resnet18().to(device)\ncriterion = nn.CrossEntropyLoss()\n# optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=1e-5) \ntot_epoch = 500\ninit_lr = 0.001\nweight_decay = 1e-4\noptimizer = torch.optim.SGD(model.parameters(), lr=init_lr, weight_decay=weight_decay)\n\ndef _lr_lambda(epoch, scheduler_type='linear'):\n    lr_bias = 0.01  # lr_bias越大lr的下降速度越慢，整个epoch跑完最后的lr值也越大\n    if scheduler_type == 'linear':\n        return (1 - epoch / (tot_epoch - 1)) * (1. - lr_bias) + lr_bias\n    elif scheduler_type == 'cosine':\n        return ((1 + math.cos(epoch * math.pi / tot_epoch)) / 2) * (1. - lr_bias) + lr_bias  # cosine\n    else:\n        return math.pow(1 - epoch / tot_epoch, 0.9)\n    \nlr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer, lr_lambda=_lr_lambda)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:16:24.190527Z","iopub.execute_input":"2022-03-20T08:16:24.191238Z","iopub.status.idle":"2022-03-20T08:16:24.53627Z","shell.execute_reply.started":"2022-03-20T08:16:24.191201Z","shell.execute_reply":"2022-03-20T08:16:24.535215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"use_cuda = True if device == \"cuda\" else False\nscaler = amp.GradScaler(enabled=use_cuda)  # mix precision training\nema_model = ExponentialMovingAverageModel(model, tot_epoch=tot_epoch)\naccumulate = 256","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:16:24.537663Z","iopub.execute_input":"2022-03-20T08:16:24.537916Z","iopub.status.idle":"2022-03-20T08:16:24.612526Z","shell.execute_reply.started":"2022-03-20T08:16:24.537885Z","shell.execute_reply":"2022-03-20T08:16:24.611571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## trainer","metadata":{}},{"cell_type":"code","source":"def train(model, train_loader, criterion, optimizer, lr_scheduler, n_epochs=100):\n    \n    patience = 30 # If no improvement in 'patience' epochs, early stop\n    \n    stale = 0\n    best_acc = 0\n\n    for epoch in range(n_epochs):\n        model.train()\n        # These are used to record information in training.\n        train_loss = []\n        train_accs = []\n        for i, batch in enumerate(tqdm(train_loader)):\n            cur_steps = epoch * len(train_loader) + i + 1\n            imgs, labels = batch\n            #imgs = imgs.half()\n            \n            # ==================================\n            with amp.autocast(enabled=use_cuda):\n                logits = model(imgs.to(device))\n                loss = criterion(logits, labels.to(device)) / (accumulate / batch_size)\n            # backward\n            scaler.scale(loss).backward()\n             # optimize\n            if cur_steps % accumulate == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                ema_model.update(model)\n            # ===============================\n    \n#             logits = model(imgs.to(device))\n#             loss = criterion(logits, labels.to(device))\n#             optimizer.zero_grad()\n#             loss.backward()\n#             optimizer.step()\n                    \n            grad_norm = nn.utils.clip_grad_norm_(model.parameters(), max_norm=10)\n            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n            train_loss.append(loss.item())\n            train_accs.append(acc)\n\n        train_loss = sum(train_loss) / len(train_loss)\n        train_acc = sum(train_accs) / len(train_accs)\n\n        # Print the information.\n        lr = lr_scheduler.get_last_lr()[0]\n        print(f\"[ Train | {epoch + 1:03d}/{n_epochs:03d} ] loss = {train_loss:.5f}, acc = {train_acc:.5f}, lr = {lr:.2e}\")\n\n        # ---------- Validation ----------\n        model.eval()\n\n        # These are used to record information in validation.\n        valid_loss = []\n        valid_accs = []\n\n        # Iterate the validation set by batches.\n        for batch in tqdm(valid_loader):\n            imgs, labels = batch\n            #imgs = imgs.half()\n\n            with torch.no_grad():\n                logits = model(imgs.to(device))\n\n            loss = criterion(logits, labels.to(device))\n            acc = (logits.argmax(dim=-1) == labels.to(device)).float().mean()\n\n            # Record the loss and accuracy.\n            valid_loss.append(loss.item())\n            valid_accs.append(acc)\n\n        # The average loss and accuracy for entire validation set is the average of the recorded values.\n        valid_loss = sum(valid_loss) / len(valid_loss)\n        valid_acc = sum(valid_accs) / len(valid_accs)\n\n        # Print the information.\n        print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n        # update logs\n        if valid_acc > best_acc:\n            with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f} -> best\")\n        else:\n            with open(f\"./{_exp_name}_log.txt\",\"a\"):\n                print(f\"[ Valid | {epoch + 1:03d}/{n_epochs:03d} ] loss = {valid_loss:.5f}, acc = {valid_acc:.5f}\")\n\n        # save models\n        if valid_acc > best_acc:\n            print(f\"Best model found at epoch {epoch}, saving model\")\n            torch.save(ema_model.ema.state_dict(), f\"./ema_{_exp_name}_best.ckpt\") # only save best to prevent output memory exceed error\n            torch.save(model.state_dict(), f\"./{_exp_name}_best.ckpt\")\n            best_acc = valid_acc\n            stale = 0\n            print(f\"model_path: {Path(f'./{_exp_name}_best.ckpt').resolve()}\")\n        else:\n            stale += 1\n            if stale > patience:\n                print(f\"No improvment {patience} consecutive epochs, early stopping\")\n                break\n        lr_scheduler.step()","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:16:24.614241Z","iopub.execute_input":"2022-03-20T08:16:24.614526Z","iopub.status.idle":"2022-03-20T08:16:24.635706Z","shell.execute_reply.started":"2022-03-20T08:16:24.614472Z","shell.execute_reply":"2022-03-20T08:16:24.634936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(model, train_loader, criterion, optimizer, lr_scheduler, n_epochs=tot_epoch)","metadata":{"papermill":{"duration":32830.720158,"end_time":"2022-02-23T19:10:19.001001","exception":false,"start_time":"2022-02-23T10:03:08.280843","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:16:24.637081Z","iopub.execute_input":"2022-03-20T08:16:24.637533Z","iopub.status.idle":"2022-03-20T08:17:27.954234Z","shell.execute_reply.started":"2022-03-20T08:16:24.637465Z","shell.execute_reply":"2022-03-20T08:17:27.952368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing and generate prediction CSV","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)","metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:17:27.955539Z","iopub.status.idle":"2022-03-20T08:17:27.955885Z","shell.execute_reply.started":"2022-03-20T08:17:27.955709Z","shell.execute_reply":"2022-03-20T08:17:27.955727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### TTA","metadata":{}},{"cell_type":"code","source":"def predict(model, model_path, test_loader, tta):\n    def pad4(i):\n        return \"0\"*(4-len(str(i)))+str(i)\n    \n    probs = []\n    prediction = []\n    model.load_state_dict(torch.load(model_path))\n    model.eval()\n    with torch.no_grad():\n        for data,_ in test_loader:\n            if tta:\n                data = data.to(device)\n                test_pred_vertical_flip = model(torch.flip(data, dims=[2]))  # vertical flip\n                test_pred_horizontal_flip = model(torch.flip(data, dims=[3]))  # horizontal flip\n                test_pred = test_pred_vertical_flip * 0.5 + test_pred_horizontal_flip * 0.5  # (bs, cls_num)\n            else:\n                test_pred = model(data.to(device))  # (bs, cls_num)\n                \n            probs.append(test_pred.cpu().numpy())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            prediction += test_label.squeeze().tolist()\n            \n    df = pd.DataFrame()\n    df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n    df[\"Category\"] = prediction\n    df.to_csv(f\"submission_{Path(model_path).stem}.csv\",index = False)\n    return np.concatenate(probs, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:17:27.957663Z","iopub.status.idle":"2022-03-20T08:17:27.958068Z","shell.execute_reply.started":"2022-03-20T08:17:27.957877Z","shell.execute_reply":"2022-03-20T08:17:27.957898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet18().to(device)\nmodel_path = \"./ema_sample_best.ckpt\"\nprobs = predict(model, model_path, test_loader, True)","metadata":{"execution":{"iopub.status.busy":"2022-03-20T08:17:27.959775Z","iopub.status.idle":"2022-03-20T08:17:27.960226Z","shell.execute_reply.started":"2022-03-20T08:17:27.960001Z","shell.execute_reply":"2022-03-20T08:17:27.960041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_best = Classifier().to(device)\n# model_best.load_state_dict(torch.load(f\"{_exp_name}_best.ckpt\"))\n# model_best.eval()\n# prediction = []\n# with torch.no_grad():\n#     for data,_ in test_loader:\n#         test_pred = model_best(data.to(device))\n#         test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n#         prediction += test_label.squeeze().tolist()","metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:17:27.962634Z","iopub.status.idle":"2022-03-20T08:17:27.963615Z","shell.execute_reply.started":"2022-03-20T08:17:27.963326Z","shell.execute_reply":"2022-03-20T08:17:27.963354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create test csv\n# def pad4(i):\n#     return \"0\"*(4-len(str(i)))+str(i)\n# df = pd.DataFrame()\n# df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n# df[\"Category\"] = prediction\n# df.to_csv(\"submission.csv\",index = False)","metadata":{"papermill":{"duration":0.554276,"end_time":"2022-02-23T19:11:11.870035","exception":false,"start_time":"2022-02-23T19:11:11.315759","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-20T08:17:27.964812Z","iopub.status.idle":"2022-03-20T08:17:27.96583Z","shell.execute_reply.started":"2022-03-20T08:17:27.965516Z","shell.execute_reply":"2022-03-20T08:17:27.965548Z"},"trusted":true},"execution_count":null,"outputs":[]}]}