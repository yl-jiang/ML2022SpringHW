{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# If you want to access the version you have already modified, click \"Edit\"\n# If you want to access the original sample code, click \"...\", then click \"Copy & Edit Notebook\"","metadata":{}},{"cell_type":"code","source":"_exp_name = \"sample\"","metadata":{"papermill":{"duration":0.0189,"end_time":"2022-02-23T10:03:06.279758","exception":false,"start_time":"2022-02-23T10:03:06.260858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:32.091367Z","iopub.execute_input":"2022-03-26T10:06:32.092049Z","iopub.status.idle":"2022-03-26T10:06:32.120795Z","shell.execute_reply.started":"2022-03-26T10:06:32.091942Z","shell.execute_reply":"2022-03-26T10:06:32.119906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import necessary packages.\nimport numpy as np\nimport torch\nimport os\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# \"ConcatDataset\" and \"Subset\" are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset, Dataset\nfrom torchvision.datasets import DatasetFolder, VisionDataset\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\nimport random\nfrom torch.cuda import amp\nfrom pathlib import Path\nimport pandas as pd","metadata":{"papermill":{"duration":1.654263,"end_time":"2022-02-23T10:03:07.947242","exception":false,"start_time":"2022-02-23T10:03:06.292979","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:32.127435Z","iopub.execute_input":"2022-03-26T10:06:32.12768Z","iopub.status.idle":"2022-03-26T10:06:33.959571Z","shell.execute_reply.started":"2022-03-26T10:06:32.127651Z","shell.execute_reply":"2022-03-26T10:06:33.95858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"myseed = 6666  # set a random seed for reproducibility\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(myseed)\ntorch.manual_seed(myseed)\nif torch.cuda.is_available():\n    torch.cuda.manual_seed_all(myseed)","metadata":{"papermill":{"duration":0.078771,"end_time":"2022-02-23T10:03:08.039428","exception":false,"start_time":"2022-02-23T10:03:07.960657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:33.96266Z","iopub.execute_input":"2022-03-26T10:06:33.963606Z","iopub.status.idle":"2022-03-26T10:06:34.016886Z","shell.execute_reply.started":"2022-03-26T10:06:33.963562Z","shell.execute_reply":"2022-03-26T10:06:34.015911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Transforms**\nTorchvision provides lots of useful utilities for image preprocessing, data wrapping as well as data augmentation.\n\nPlease refer to PyTorch official website for details about different transforms.","metadata":{"papermill":{"duration":0.01289,"end_time":"2022-02-23T10:03:08.065357","exception":false,"start_time":"2022-02-23T10:03:08.052467","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Normally, We don't need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n])","metadata":{"papermill":{"duration":0.021406,"end_time":"2022-02-23T10:03:08.099437","exception":false,"start_time":"2022-02-23T10:03:08.078031","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:34.018417Z","iopub.execute_input":"2022-03-26T10:06:34.018714Z","iopub.status.idle":"2022-03-26T10:06:34.025019Z","shell.execute_reply.started":"2022-03-26T10:06:34.018671Z","shell.execute_reply":"2022-03-26T10:06:34.023733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Datasets**\nThe data is labelled by the name, so we load images and label while calling '__getitem__'","metadata":{"papermill":{"duration":0.012739,"end_time":"2022-02-23T10:03:08.125181","exception":false,"start_time":"2022-02-23T10:03:08.112442","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class FoodDataset(Dataset):\n\n    def __init__(self,path,tfm=test_tfm,files = None):\n        super(FoodDataset).__init__()\n        self.path = path\n        self.files = sorted([os.path.join(path,x) for x in os.listdir(path) if x.endswith(\".jpg\")])\n        if files != None:\n            self.files = files\n        print(f\"One {path} sample\",self.files[0])\n        self.transform = tfm\n  \n    def __len__(self):\n        return len(self.files)\n  \n    def __getitem__(self,idx):\n        fname = self.files[idx]\n        im = Image.open(fname)\n        im = self.transform(im)\n        #im = self.data[idx]\n        try:\n            label = int(fname.split(\"/\")[-1].split(\"_\")[0])\n        except:\n            label = -1 # test has no label\n        return im,label\n","metadata":{"papermill":{"duration":0.023022,"end_time":"2022-02-23T10:03:08.160912","exception":false,"start_time":"2022-02-23T10:03:08.13789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:34.028617Z","iopub.execute_input":"2022-03-26T10:06:34.029367Z","iopub.status.idle":"2022-03-26T10:06:34.041697Z","shell.execute_reply.started":"2022-03-26T10:06:34.029321Z","shell.execute_reply":"2022-03-26T10:06:34.040535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"class Bottleneck(nn.Module):\n    expansion = 4\n \n    def __init__(self, inplanes, planes, stride=1, downsample=None):\n        super(Bottleneck, self).__init__()\n        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n        self.relu = nn.ReLU(inplace=True)\n        self.downsample = downsample\n        self.stride = stride\n \n    def forward(self, x):\n        residual = x\n \n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n \n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n \n        out = self.conv3(out)\n        out = self.bn3(out)\n \n        if self.downsample is not None:\n            residual = self.downsample(x)\n \n        out += residual\n        out = self.relu(out)\n \n        return out\n\n\nclass ResNet(nn.Module):\n \n    def __init__(self, block, layers, num_classes=1000):\n        self.inplanes = 64\n        super(ResNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu = nn.ReLU(inplace=True)\n        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n        self.layer1 = self._make_layer(block, 64, layers[0])\n        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n        self.avgpool = nn.AvgPool2d(7, stride=1)\n        self.fc = nn.Linear(512 * block.expansion, num_classes)\n \n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.constant_(m.weight, 1)\n                nn.init.constant_(m.bias, 0)\n \n    def _make_layer(self, block, planes, blocks, stride=1):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(self.inplanes, planes * block.expansion, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n \n        layers = []\n        layers.append(block(self.inplanes, planes, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes))\n \n        return nn.Sequential(*layers)\n \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n \n        x = self.avgpool(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc(x)\n \n        return x\n\n\ndef resnet18(pretrained=False, num_classes=11):\n    \"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"\n    model = ResNet(Bottleneck, [2, 2, 2, 2], num_classes)\n    if pretrained:\n        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:06:34.04351Z","iopub.execute_input":"2022-03-26T10:06:34.044177Z","iopub.status.idle":"2022-03-26T10:06:34.074626Z","shell.execute_reply.started":"2022-03-26T10:06:34.044118Z","shell.execute_reply":"2022-03-26T10:06:34.073507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## dataloader","metadata":{}},{"cell_type":"code","source":"batch_size = 64\n_dataset_dir = \"../input/ml2022spring-hw3b/food11\"","metadata":{"papermill":{"duration":0.054295,"end_time":"2022-02-23T10:03:08.266338","exception":false,"start_time":"2022-02-23T10:03:08.212043","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:34.076122Z","iopub.execute_input":"2022-03-26T10:06:34.077474Z","iopub.status.idle":"2022-03-26T10:06:34.090578Z","shell.execute_reply.started":"2022-03-26T10:06:34.077428Z","shell.execute_reply":"2022-03-26T10:06:34.089635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# Initialize a model, and put it on the device specified.\nmodel = resnet18().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:06:34.092337Z","iopub.execute_input":"2022-03-26T10:06:34.09271Z","iopub.status.idle":"2022-03-26T10:06:37.873647Z","shell.execute_reply.started":"2022-03-26T10:06:34.092641Z","shell.execute_reply":"2022-03-26T10:06:37.872615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing and generate prediction CSV","metadata":{"papermill":{"duration":0.498773,"end_time":"2022-02-23T19:10:20.961802","exception":false,"start_time":"2022-02-23T19:10:20.463029","status":"completed"},"tags":[]}},{"cell_type":"code","source":"test_set = FoodDataset(os.path.join(_dataset_dir,\"test\"), tfm=test_tfm)\ntest_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=0, pin_memory=True)","metadata":{"papermill":{"duration":0.493644,"end_time":"2022-02-23T19:10:19.985992","exception":false,"start_time":"2022-02-23T19:10:19.492348","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T10:06:37.876847Z","iopub.execute_input":"2022-03-26T10:06:37.877671Z","iopub.status.idle":"2022-03-26T10:06:38.276659Z","shell.execute_reply.started":"2022-03-26T10:06:37.877638Z","shell.execute_reply":"2022-03-26T10:06:38.275601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, model_path, test_loader, tta):\n    def pad4(i):\n        return \"0\"*(4-len(str(i)))+str(i)\n    \n    probs = []\n    prediction = []\n    model.load_state_dict(torch.load(model_path))\n    print(f\"use pretrained model: {model_path}\")\n    model.eval()\n    with torch.no_grad():\n        for data,_ in tqdm(test_loader):\n            if tta:\n                data = data.to(device)\n                test_pred_vertical_flip = model(torch.flip(data, dims=[2]))  # vertical flip\n                test_pred_horizontal_flip = model(torch.flip(data, dims=[3]))  # horizontal flip\n                test_pred = test_pred_vertical_flip * 0.5 + test_pred_horizontal_flip * 0.5  # (bs, cls_num)\n            else:\n                test_pred = model(data.to(device))  # (bs, cls_num)\n                \n            probs.append(test_pred.cpu().numpy())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            prediction += test_label.squeeze().tolist()\n            \n    df = pd.DataFrame()\n    df[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\n    df[\"Category\"] = prediction\n    if tta:\n        df.to_csv(f\"submission_{Path(model_path).stem}_tta.csv\",index = False)\n    else:\n        df.to_csv(f\"submission_{Path(model_path).stem}.csv\",index = False)\n    return np.concatenate(probs, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:10:18.761603Z","iopub.execute_input":"2022-03-26T10:10:18.761946Z","iopub.status.idle":"2022-03-26T10:10:18.777274Z","shell.execute_reply.started":"2022-03-26T10:10:18.761893Z","shell.execute_reply":"2022-03-26T10:10:18.776135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TTA","metadata":{}},{"cell_type":"code","source":"model = resnet18().to(device)\nmodel_path = \"../input/emak40/ema_sample_best.ckpt\"\nprobs = predict(model, model_path, test_loader, True)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:07:36.925231Z","iopub.execute_input":"2022-03-26T10:07:36.925601Z","iopub.status.idle":"2022-03-26T10:08:45.420448Z","shell.execute_reply.started":"2022-03-26T10:07:36.925569Z","shell.execute_reply":"2022-03-26T10:08:45.419457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnet18().to(device)\nmodel_path = \"../input/plaink40/sample_best.ckpt\"\nprobs = predict(model, model_path, test_loader, True)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T10:13:22.37866Z","iopub.execute_input":"2022-03-26T10:13:22.379493Z","iopub.status.idle":"2022-03-26T10:14:03.133969Z","shell.execute_reply.started":"2022-03-26T10:13:22.379448Z","shell.execute_reply":"2022-03-26T10:14:03.13275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pad4(i):\n    return \"0\"*(4-len(str(i)))+str(i)\n\nmodel_pathes = [\"../input/emak40/ema_sample_best.ckpt\", \"../input/orginal/resnet18_org2.ckpt\", \"../input/plaink40/sample_best.ckpt\"]\nprobs = []\npredictions = []\ntta = True\nfor model_path in model_pathes:\n    model.load_state_dict(torch.load(model_path))\n    print(f\"use pretrained model: {model_path}\")\n    tmp_probs, tmp_pred = [], []\n    model.eval()\n    with torch.no_grad():\n        for data,_ in tqdm(test_loader):\n            if tta:\n                data = data.to(device)\n                test_pred_vertical_flip = model(torch.flip(data, dims=[2]))  # vertical flip\n                test_pred_horizontal_flip = model(torch.flip(data, dims=[3]))  # horizontal flip\n                test_pred = test_pred_vertical_flip * 0.5 + test_pred_horizontal_flip * 0.5  # (bs, cls_num)\n            else:\n                test_pred = model(data.to(device))  # (bs, cls_num)\n            \n            tmp_probs.append(test_pred.cpu().numpy())\n            test_label = np.argmax(test_pred.cpu().data.numpy(), axis=1)\n            tmp_pred += test_label.squeeze().tolist()\n    probs.append(tmp_probs)\n    predictions.append(tmp_pred)","metadata":{"papermill":{"duration":49.157727,"end_time":"2022-02-23T19:11:10.61523","exception":false,"start_time":"2022-02-23T19:10:21.457503","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-26T11:11:50.823345Z","iopub.execute_input":"2022-03-26T11:11:50.823677Z","iopub.status.idle":"2022-03-26T11:13:47.777996Z","shell.execute_reply.started":"2022-03-26T11:11:50.823647Z","shell.execute_reply":"2022-03-26T11:13:47.777072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ensemble Probalities","metadata":{}},{"cell_type":"code","source":"all_probs1 = np.concatenate(probs[0], axis=0)\nall_probs2 = np.concatenate(probs[1], axis=0)\nall_probs3 = np.concatenate(probs[2], axis=0)\nprint(all_probs2.shape)\n\nall_probs = all_probs1 * 0.33 + all_probs2 * 0.33  + all_probs3 * 0.33\nall_label1 = np.argmax(all_probs, axis=1)\nprint(all_label1.shape)\n\ndf = pd.DataFrame()\ndf[\"Id\"] = [pad4(i) for i in range(1,len(test_set)+1)]\ndf[\"Category\"] = all_label1\ndf.to_csv(f\"ensemble_prob.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T11:15:18.508728Z","iopub.execute_input":"2022-03-26T11:15:18.509093Z","iopub.status.idle":"2022-03-26T11:15:18.535911Z","shell.execute_reply.started":"2022-03-26T11:15:18.509061Z","shell.execute_reply":"2022-03-26T11:15:18.535092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ensemble Votting","metadata":{}},{"cell_type":"code","source":"len(predictions)","metadata":{"execution":{"iopub.status.busy":"2022-03-26T11:02:25.612713Z","iopub.execute_input":"2022-03-26T11:02:25.613519Z","iopub.status.idle":"2022-03-26T11:02:25.619955Z","shell.execute_reply.started":"2022-03-26T11:02:25.613479Z","shell.execute_reply":"2022-03-26T11:02:25.618914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import Counter\n\nfor lab1, lab2, lab3 in zip(*predictions):\n    counter = Counter([lab1, lab2, lab3])\n    \n    idx = list(counter.keys())\n    lab = list(counter.values())","metadata":{},"execution_count":null,"outputs":[]}]}