{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom torch.nn.utils.rnn import pad_sequence","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:20.770704Z","iopub.execute_input":"2022-03-16T07:16:20.771173Z","iopub.status.idle":"2022-03-16T07:16:22.307784Z","shell.execute_reply.started":"2022-03-16T07:16:20.771080Z","shell.execute_reply":"2022-03-16T07:16:22.306987Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"def load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n    class_num = 41 # NOTE: pre-computed, should not need change\n    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n\n    label_dict = {}\n    if mode != 'test':\n        phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n        for line in phone_file:\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n\n    if split == 'train' or split == 'val':\n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(train_val_seed)\n        random.shuffle(usage_list)\n        percent = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n    elif split == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    X = []\n    if mode != 'test':\n        y = []\n    \n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        feat = concat_feat(feat, concat_nframes)\n        X.append(feat)\n        \n        if mode != 'test':\n            label = torch.LongTensor(label_dict[fname])\n\n        if mode != 'test':\n            y.append(label)\n\n    print(f'[INFO] {split} set')\n    print(len(X))\n    if mode != 'test':\n        print(len(y))\n        return X, y\n    else:\n        return X","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:22.309818Z","iopub.execute_input":"2022-03-16T07:16:22.310154Z","iopub.status.idle":"2022-03-16T07:16:22.330854Z","shell.execute_reply.started":"2022-03-16T07:16:22.310120Z","shell.execute_reply":"2022-03-16T07:16:22.329976Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### what the function concat_n do?","metadata":{}},{"cell_type":"code","source":"x = torch.tensor([[1, 1, 1], [2, 2, 2], [3, 3, 3], [4, 4, 4]]) # (seq_len, feat_dim)\nprint(f\"before concat:\\n{x}\")\nseq_len, feature_dim = x.size(0), x.size(1)\nconcat_n = 3\nx = x.repeat(1, concat_n) \n# print(x)\nx = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n# print(x)\nmid = (concat_n // 2)\nfor r_idx in range(1, mid+1):\n    x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n    x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n# print(x)\nx = x.permute(1, 0, 2)  # (seq_len, concat_n, feat_dim)\n# print(x)\nx = x.view(seq_len, concat_n * feature_dim)\nprint(f\"after concate:\\n{x}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:22.332736Z","iopub.execute_input":"2022-03-16T07:16:22.333031Z","iopub.status.idle":"2022-03-16T07:16:22.377510Z","shell.execute_reply.started":"2022-03-16T07:16:22.332982Z","shell.execute_reply":"2022-03-16T07:16:22.376721Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"x_ = torch.load('/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat/train/2007-149877-0023.pt')\nf_ = open('/kaggle/input/ml2022spring-hw2/libriphone/libriphone/train_labels.txt').readlines()\nfilename = f_[0].strip('\\n').split(' ')[0]\nprint(filename)\ny_ = line = f_[0].strip('\\n').split(' ')[1:]\nx_.shape, len(y_)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:22.380116Z","iopub.execute_input":"2022-03-16T07:16:22.380507Z","iopub.status.idle":"2022-03-16T07:16:22.490598Z","shell.execute_reply.started":"2022-03-16T07:16:22.380470Z","shell.execute_reply":"2022-03-16T07:16:22.489859Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{}},{"cell_type":"code","source":"X, y = preprocess_data('train', feat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat', phone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone', concat_nframes=1, train_ratio=0.8, train_val_seed=1337)\n\nfrom torch.nn.utils.rnn import pad_sequence\ntrain_x = pad_sequence(X)  # (seq_len, data_len, feat_dim)\ntrain_y = pad_sequence(y)  # (seq_len, data_len)\n\ntrain_x.shape, train_y.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:22.493326Z","iopub.execute_input":"2022-03-16T07:16:22.493737Z","iopub.status.idle":"2022-03-16T07:16:47.134294Z","shell.execute_reply.started":"2022-03-16T07:16:22.493690Z","shell.execute_reply":"2022-03-16T07:16:47.133447Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = pad_sequence(X)  # (seq_len, batch_size, feat_dim)\n        \n        if y is not None:\n            y = pad_sequence(y)\n            self.label = y.long()\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[:, idx, :], self.label[:, idx]\n        else:\n            return self.data[:, idx, :]\n\n    def __len__(self):\n        return self.data.size(1)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:47.135801Z","iopub.execute_input":"2022-03-16T07:16:47.136087Z","iopub.status.idle":"2022-03-16T07:16:47.143627Z","shell.execute_reply.started":"2022-03-16T07:16:47.136049Z","shell.execute_reply":"2022-03-16T07:16:47.142850Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim=39, mid_dim=256, mid_layers=2, out_dim=41, bidirectional=True):\n        super(LSTMClassifier, self).__init__()\n        \n        self.rnn1 = nn.LSTM(input_dim, mid_dim, mid_layers, bidirectional=bidirectional)  # rnn\n        if not bidirectional:\n            self.reg = nn.Sequential(\n                nn.Linear(mid_dim, mid_dim // 2),\n                nn.LayerNorm(mid_dim // 2),\n                nn.Dropout(p=0.2),\n                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n                nn.Linear(mid_dim // 2, out_dim),\n            )  # regression\n        else:\n            print(\"use bidirectional lstm\")\n            self.reg = nn.Sequential(\n                nn.Linear(mid_dim * 2, mid_dim),\n                nn.LayerNorm(mid_dim),\n                nn.Dropout(p=0.3),\n                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n                nn.Linear(mid_dim, out_dim),\n            )  # regression\n\n    def forward(self, x):\n        out, (h, c) = self.rnn1(x)  # (seq_len, batch_size, mid_dim), [(num_layers, batch_size, mid_dim), (num_layers, batch_size, mid_dim)]\n#         out, (h, c) = self.rnn2(out, )\n        x = self.reg(out)  # (seq_len, batch_size, out_dim)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:47.145163Z","iopub.execute_input":"2022-03-16T07:16:47.145416Z","iopub.status.idle":"2022-03-16T07:16:47.156712Z","shell.execute_reply.started":"2022-03-16T07:16:47.145381Z","shell.execute_reply":"2022-03-16T07:16:47.155946Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"## hyper-parameters","metadata":{}},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 3              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\ntrain_ratio = 0.9               # the ratio of data used for training, the rest will be used for validation\n\n# training parameters\nseed = 42                        # random seed\nbatch_size =128                  # batch size\nnum_epoch = 1000                 # the number of training epoch\nlearning_rate = 1e-4            # learning rate\nweight_decay = 1e-3\nmodel_path = './model.ckpt'     # the path where the checkpoint will be saved\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nhidden_layers = 1               # the number of hidden layers\nmid_dim = 256                   # the hidden dim\nmid_layers = 3\npatient = 30                    #  if val_acc exceed 30 epoches are not promoted then stop training\nbidirectional = True\n\nseq_len = train_x.size(0)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:47.157841Z","iopub.execute_input":"2022-03-16T07:16:47.158473Z","iopub.status.idle":"2022-03-16T07:16:47.168382Z","shell.execute_reply.started":"2022-03-16T07:16:47.158418Z","shell.execute_reply":"2022-03-16T07:16:47.167659Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"import gc\n\nfeat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat/'\nphone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/'\n\n# preprocess data\ntrain_X, train_y = preprocess_data(split='train', feat_dir=feat_dir, phone_path=phone_path, concat_nframes=concat_nframes, train_ratio=train_ratio)\nval_X, val_y = preprocess_data(split='val', feat_dir=feat_dir, phone_path=phone_path, concat_nframes=concat_nframes, train_ratio=train_ratio)\n\n# get dataset\ntrain_set = LibriDataset(train_X, train_y)\nval_set = LibriDataset(val_X, val_y)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:16:47.169666Z","iopub.execute_input":"2022-03-16T07:16:47.169966Z","iopub.status.idle":"2022-03-16T07:17:00.475544Z","shell.execute_reply.started":"2022-03-16T07:16:47.169916Z","shell.execute_reply":"2022-03-16T07:17:00.474755Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# remove raw feature to save memory\ndel train_X, train_y, val_X, val_y\ngc.collect()\n\n# get dataloader\ntrain_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:17:00.476903Z","iopub.execute_input":"2022-03-16T07:17:00.477181Z","iopub.status.idle":"2022-03-16T07:17:00.598144Z","shell.execute_reply.started":"2022-03-16T07:17:00.477145Z","shell.execute_reply":"2022-03-16T07:17:00.597424Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:17:00.599598Z","iopub.execute_input":"2022-03-16T07:17:00.599853Z","iopub.status.idle":"2022-03-16T07:17:00.645147Z","shell.execute_reply.started":"2022-03-16T07:17:00.599818Z","shell.execute_reply":"2022-03-16T07:17:00.644354Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## random seed","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\n#fix seed\ndef same_seeds(seed):\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)  \n    np.random.seed(seed)  \n    torch.backends.cudnn.benchmark = False\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:17:00.646630Z","iopub.execute_input":"2022-03-16T07:17:00.646905Z","iopub.status.idle":"2022-03-16T07:17:00.654873Z","shell.execute_reply.started":"2022-03-16T07:17:00.646866Z","shell.execute_reply":"2022-03-16T07:17:00.654057Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"### fix random seed\nsame_seeds(seed)\n\n# create model, define a loss function, and optimizer\nmodel = LSTMClassifier(input_dim=input_dim, mid_dim=mid_dim, mid_layers=mid_layers, out_dim=41, bidirectional=bidirectional).to(device)\ncriterion = nn.CrossEntropyLoss() \noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)","metadata":{"execution":{"iopub.status.busy":"2022-03-16T07:17:00.657589Z","iopub.execute_input":"2022-03-16T07:17:00.658501Z","iopub.status.idle":"2022-03-16T07:17:03.549458Z","shell.execute_reply.started":"2022-03-16T07:17:00.658469Z","shell.execute_reply":"2022-03-16T07:17:03.548703Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## training","metadata":{}},{"cell_type":"code","source":"best_acc = 0.0\nearly_stop = 0\nfor epoch in range(num_epoch):\n    train_acc = 0.0\n    train_loss = 0.0\n    val_acc = 0.0\n    val_loss = 0.0\n    \n    # training\n    model.train() # set the model to training mode\n    for i, batch in enumerate(tqdm(train_loader)):\n        features, labels = batch\n        features = features.permute(1, 0, 2).to(device)  # (seq_len, batch_size, feat_dim)\n        labels = labels.permute(1, 0).to(device)  # (seq_len, batch_size)\n        \n        optimizer.zero_grad() \n        outputs = model(features)  # (seq_len, batch_size, cls_num)\n        # print(features.shape, labels.shape, outputs.shape)\n        loss = criterion(outputs.permute(0, 2, 1), labels)  # (seq_len, cls_num, batch_size) & (seq_len, batch_size)\n        loss.backward() \n        optimizer.step() \n        \n        _, train_pred = torch.max(outputs.permute(1, 0, 2), -1) # get the index of the class with the highest probability / (batch_size, seq_len)\n        train_acc += (train_pred.detach() == labels.permute(1, 0).detach()).sum().item()\n        train_loss += loss.item()\n    \n    # validation\n    if len(val_set) > 0:\n        model.eval() # set the model to evaluation mode\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(val_loader)):\n                features, labels = batch\n                features = features.permute(1, 0, 2).to(device)\n                labels = labels.permute(1, 0).to(device)\n                outputs = model(features)\n                \n                loss = criterion(outputs.permute(0, 2, 1), labels) \n                \n                _, val_pred = torch.max(outputs.permute(1, 0, 2), -1) \n                val_acc += (val_pred.cpu() == labels.permute(1, 0).cpu()).sum().item() # get the index of the class with the highest probability\n                val_loss += loss.item()\n\n            print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f} | Val Acc: {:3.6f} loss: {:3.6f}'.format(\n                epoch + 1, num_epoch, train_acc/(len(train_set)* seq_len), train_loss/(len(train_loader)), val_acc/(len(val_set)* seq_len), val_loss/len(val_loader)\n            ))\n\n            # if the model improves, save a checkpoint at this epoch\n            if early_stop <= patient:\n                if val_acc > best_acc:\n                    early_stop = 0\n                    best_acc = val_acc\n                    torch.save(model.state_dict(), model_path)\n                    print('saving model with acc {:.3f}'.format(best_acc/(len(val_set) * seq_len)))\n                else:\n                    early_stop += 1\n    else:\n        print('[{:03d}/{:03d}] Train Acc: {:3.6f} Loss: {:3.6f}'.format(epoch + 1, num_epoch, train_acc/(len(train_set) * seq_len), train_loss/(len(train_loader))))\n    \n    if early_stop > patient:\n        a = input()\n\n# if not validating, save the last epoch\nif len(val_set) == 0:\n    torch.save(model.state_dict(), model_path)\n    print('saving model at last epoch')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-16T07:17:03.552210Z","iopub.execute_input":"2022-03-16T07:17:03.552455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del train_loader, val_loader\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## testing","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nclass LibriTestDataset(Dataset):\n    def __init__(self, X):\n        \n        self.data = X\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\ntest_X = preprocess_data(split='test', feat_dir=feat_dir, phone_path=phone_path, concat_nframes=concat_nframes)\ntest_set = LibriTestDataset(test_X)\ntest_loader = DataLoader(test_set, batch_size=1, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_X), test_X[0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = LSTMClassifier(input_dim=input_dim, mid_dim=mid_dim, mid_layers=mid_layers, out_dim=41).to(device)\nmodel.load_state_dict(torch.load(model_path))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc = 0.0\ntest_lengths = 0\npred = np.array([], dtype=np.int32)\n\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features = batch\n        features = features.permute(1, 0, 2).to(device)  # (seq_len, batch_size, feat_dim)\n        outputs = model(features)  # (seq_len, batch_size, cls_num)\n\n        _, test_pred = torch.max(outputs.permute(1, 0, 2), -1) # get the index of the class with the highest probability / (batch_size, seq_len)\n        pred = np.concatenate((pred, test_pred.squeeze().cpu().numpy()), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('prediction.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}