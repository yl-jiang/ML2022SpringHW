{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport pandas as pd\nimport torch\nfrom tqdm import tqdm\nfrom torch.nn.utils.rnn import pad_sequence\nimport numpy as np","metadata":{"papermill":{"duration":1.608762,"end_time":"2022-03-18T09:36:22.474872","exception":false,"start_time":"2022-03-18T09:36:20.86611","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:16.882432Z","iopub.execute_input":"2022-03-19T07:05:16.882746Z","iopub.status.idle":"2022-03-19T07:05:18.351501Z","shell.execute_reply.started":"2022-03-19T07:05:16.88271Z","shell.execute_reply":"2022-03-19T07:05:18.350663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_feat(path):\n    feat = torch.load(path)\n    return feat\n\ndef shift(x, n):\n    if n < 0:\n        left = x[0].repeat(-n, 1)\n        right = x[:n]\n\n    elif n > 0:\n        right = x[-1].repeat(n, 1)\n        left = x[n:]\n    else:\n        return x\n\n    return torch.cat((left, right), dim=0)\n\n\ndef concat_feat(x, concat_n):\n    assert concat_n % 2 == 1 # n must be odd\n    if concat_n < 2:\n        return x\n    seq_len, feature_dim = x.size(0), x.size(1)\n    x = x.repeat(1, concat_n) \n    x = x.view(seq_len, concat_n, feature_dim).permute(1, 0, 2) # concat_n, seq_len, feature_dim\n    mid = (concat_n // 2)\n    for r_idx in range(1, mid+1):\n        x[mid + r_idx, :] = shift(x[mid + r_idx], r_idx)\n        x[mid - r_idx, :] = shift(x[mid - r_idx], -r_idx)\n\n    return x.permute(1, 0, 2).view(seq_len, concat_n * feature_dim)\n\n\ndef preprocess_data(split, feat_dir, phone_path, concat_nframes, train_ratio=0.8, train_val_seed=1337):\n    class_num = 41 # NOTE: pre-computed, should not need change\n    mode = 'train' if (split == 'train' or split == 'val') else 'test'\n\n    label_dict = {}\n    if mode != 'test':\n        phone_file = open(os.path.join(phone_path, f'{mode}_labels.txt')).readlines()\n        for line in phone_file:\n            line = line.strip('\\n').split(' ')\n            label_dict[line[0]] = [int(p) for p in line[1:]]\n\n    if split == 'train' or split == 'val':\n        # split training and validation data\n        usage_list = open(os.path.join(phone_path, 'train_split.txt')).readlines()\n        random.seed(train_val_seed)\n        random.shuffle(usage_list)\n        percent = int(len(usage_list) * train_ratio)\n        usage_list = usage_list[:percent] if split == 'train' else usage_list[percent:]\n    elif split == 'test':\n        usage_list = open(os.path.join(phone_path, 'test_split.txt')).readlines()\n    else:\n        raise ValueError('Invalid \\'split\\' argument for dataset: PhoneDataset!')\n\n    usage_list = [line.strip('\\n') for line in usage_list]\n    print('[Dataset] - # phone classes: ' + str(class_num) + ', number of utterances for ' + split + ': ' + str(len(usage_list)))\n\n    X = []\n    if mode != 'test':\n        y = []\n    \n    for i, fname in tqdm(enumerate(usage_list)):\n        feat = load_feat(os.path.join(feat_dir, mode, f'{fname}.pt'))\n        feat = concat_feat(feat, concat_nframes)\n        X.append(feat)\n        \n        if mode != 'test':\n            label = torch.LongTensor(label_dict[fname])\n\n        if mode != 'test':\n            y.append(label)\n\n    print(f'[INFO] {split} set')\n    print(len(X))\n    if mode != 'test':\n        print(len(y))\n        return X, y\n    else:\n        return X","metadata":{"papermill":{"duration":0.039722,"end_time":"2022-03-18T09:36:22.536734","exception":false,"start_time":"2022-03-18T09:36:22.497012","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:18.354018Z","iopub.execute_input":"2022-03-19T07:05:18.354837Z","iopub.status.idle":"2022-03-19T07:05:18.377296Z","shell.execute_reply.started":"2022-03-19T07:05:18.35478Z","shell.execute_reply":"2022-03-19T07:05:18.376596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataloader","metadata":{"papermill":{"duration":0.020932,"end_time":"2022-03-18T09:36:22.852709","exception":false,"start_time":"2022-03-18T09:36:22.831777","status":"completed"},"tags":[]}},{"cell_type":"code","source":"X, y = preprocess_data('train', feat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat', phone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone', concat_nframes=1, train_ratio=0.8, train_val_seed=1337)\n\nfrom torch.nn.utils.rnn import pad_sequence\ntrain_x = pad_sequence(X)  # (seq_len, data_len, feat_dim)\ntrain_y = pad_sequence(y)  # (seq_len, data_len)\nseq_len = train_x.size(0)\nprint(train_x.shape, train_y.shape)\n\ndel train_x, train_y","metadata":{"papermill":{"duration":17.268722,"end_time":"2022-03-18T09:36:40.14227","exception":false,"start_time":"2022-03-18T09:36:22.873548","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:18.378673Z","iopub.execute_input":"2022-03-19T07:05:18.379585Z","iopub.status.idle":"2022-03-19T07:05:44.784109Z","shell.execute_reply.started":"2022-03-19T07:05:18.379535Z","shell.execute_reply":"2022-03-19T07:05:44.783154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nclass LibriDataset(Dataset):\n    def __init__(self, X, y=None):\n        self.data = pad_sequence(X)  # (seq_len, batch_size, feat_dim)\n        \n        if y is not None:\n            y = pad_sequence(y)\n            self.label = y.long()\n        else:\n            self.label = None\n\n    def __getitem__(self, idx):\n        if self.label is not None:\n            return self.data[:, idx, :], self.label[:, idx]\n        else:\n            return self.data[:, idx, :]\n\n    def __len__(self):\n        return self.data.size(1)","metadata":{"papermill":{"duration":0.078574,"end_time":"2022-03-18T09:36:40.291258","exception":false,"start_time":"2022-03-18T09:36:40.212684","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.785655Z","iopub.execute_input":"2022-03-19T07:05:44.785906Z","iopub.status.idle":"2022-03-19T07:05:44.795439Z","shell.execute_reply.started":"2022-03-19T07:05:44.785874Z","shell.execute_reply":"2022-03-19T07:05:44.794255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## model","metadata":{"papermill":{"duration":0.069141,"end_time":"2022-03-18T09:36:40.430593","exception":false,"start_time":"2022-03-18T09:36:40.361452","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass LSTMClassifier(nn.Module):\n    def __init__(self, input_dim=39, mid_dim=256, mid_layers=2, out_dim=41, bidirectional=True):\n        super(LSTMClassifier, self).__init__()\n        \n        self.rnn1 = nn.LSTM(input_dim, mid_dim, mid_layers, bidirectional=bidirectional)  # rnn\n        if not bidirectional:\n            self.reg = nn.Sequential(\n                nn.Linear(mid_dim, mid_dim // 2),\n                nn.LayerNorm(mid_dim // 2),\n                nn.Dropout(p=0.2),\n                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n                nn.Linear(mid_dim // 2, out_dim),\n            )  # regression\n        else:\n            print(\"use bidirectional lstm\")\n            self.reg = nn.Sequential(\n                nn.Linear(mid_dim * 2, mid_dim),\n                nn.LayerNorm(mid_dim),\n                nn.Dropout(p=0.2),\n                nn.LeakyReLU(inplace=True, negative_slope=0.01),\n                nn.Linear(mid_dim, out_dim),\n            )  # regression\n\n    def forward(self, x):\n        out, (h, c) = self.rnn1(x)  # (seq_len, batch_size, mid_dim), [(num_layers, batch_size, mid_dim), (num_layers, batch_size, mid_dim)]\n#         out, (h, c) = self.rnn2(out, )\n        x = self.reg(out)  # (seq_len, batch_size, out_dim)\n        return x","metadata":{"papermill":{"duration":0.081084,"end_time":"2022-03-18T09:36:40.579717","exception":false,"start_time":"2022-03-18T09:36:40.498633","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.799295Z","iopub.execute_input":"2022-03-19T07:05:44.799764Z","iopub.status.idle":"2022-03-19T07:05:44.813808Z","shell.execute_reply.started":"2022-03-19T07:05:44.7997Z","shell.execute_reply":"2022-03-19T07:05:44.8128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## hyper-parameters","metadata":{"papermill":{"duration":0.068518,"end_time":"2022-03-18T09:36:40.716694","exception":false,"start_time":"2022-03-18T09:36:40.648176","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# data prarameters\nconcat_nframes = 5              # the number of frames to concat with, n must be odd (total 2k+1 = n frames)\n\n# model parameters\ninput_dim = 39 * concat_nframes # the input dim of the model, you should not change the value\nmid_dim = 256                   # the hidden dim\nmid_layers = 3\nbidirectional = True","metadata":{"papermill":{"duration":0.078738,"end_time":"2022-03-18T09:36:40.865099","exception":false,"start_time":"2022-03-18T09:36:40.786361","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.816704Z","iopub.execute_input":"2022-03-19T07:05:44.816982Z","iopub.status.idle":"2022-03-19T07:05:44.832962Z","shell.execute_reply.started":"2022-03-19T07:05:44.816947Z","shell.execute_reply":"2022-03-19T07:05:44.832225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'DEVICE: {device}')","metadata":{"papermill":{"duration":0.177523,"end_time":"2022-03-18T09:36:55.618999","exception":false,"start_time":"2022-03-18T09:36:55.441476","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.834152Z","iopub.execute_input":"2022-03-19T07:05:44.834467Z","iopub.status.idle":"2022-03-19T07:05:44.847336Z","shell.execute_reply.started":"2022-03-19T07:05:44.834431Z","shell.execute_reply":"2022-03-19T07:05:44.846655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## testing","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nclass LibriTestDataset(Dataset):\n    def __init__(self, X):\n        \n        self.data = X\n\n    def __getitem__(self, idx):\n        return self.data[idx]\n\n    def __len__(self):\n        return len(self.data)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.848295Z","iopub.execute_input":"2022-03-19T07:05:44.848558Z","iopub.status.idle":"2022-03-19T07:05:44.8617Z","shell.execute_reply.started":"2022-03-19T07:05:44.848525Z","shell.execute_reply":"2022-03-19T07:05:44.860614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data\nfeat_dir='/kaggle/input/ml2022spring-hw2/libriphone/libriphone/feat'\nphone_path='/kaggle/input/ml2022spring-hw2/libriphone/libriphone'\ntest_X = preprocess_data(split='test', feat_dir=feat_dir, phone_path=phone_path, concat_nframes=concat_nframes)\ntest_set = LibriTestDataset(test_X)\ntest_loader = DataLoader(test_set, batch_size=1, shuffle=False)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:44.863Z","iopub.execute_input":"2022-03-19T07:05:44.863306Z","iopub.status.idle":"2022-03-19T07:05:53.064856Z","shell.execute_reply.started":"2022-03-19T07:05:44.863269Z","shell.execute_reply":"2022-03-19T07:05:53.064191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load model\nmodel = LSTMClassifier(input_dim=input_dim, mid_dim=mid_dim, mid_layers=mid_layers, out_dim=41).to(device)\n","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"execution":{"iopub.status.busy":"2022-03-19T07:05:53.066188Z","iopub.execute_input":"2022-03-19T07:05:53.067105Z","iopub.status.idle":"2022-03-19T07:05:53.141989Z","shell.execute_reply.started":"2022-03-19T07:05:53.067062Z","shell.execute_reply":"2022-03-19T07:05:53.140945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## single model","metadata":{}},{"cell_type":"code","source":"test_acc = 0.0\ntest_lengths = 0\npred = np.array([], dtype=np.int32)\n\nmodel.load_state_dict(torch.load(\"../input/model-seed42/model.ckpt\", map_location='cpu'))\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features = batch\n        features = features.permute(1, 0, 2).to(device)  # (seq_len, batch_size, feat_dim)\n        outputs = model(features)  # (seq_len, batch_size, cls_num)\n        _, test_pred = torch.max(outputs.permute(1, 0, 2), -1) # get the index of the class with the highest probability / (batch_size, seq_len)\n        pred = np.concatenate((pred, test_pred.squeeze().cpu().numpy()), axis=0)\n    \n\nwith open('prediction_model_seed42.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:50:49.710154Z","iopub.execute_input":"2022-03-19T07:50:49.710539Z","iopub.status.idle":"2022-03-19T07:54:37.345144Z","shell.execute_reply.started":"2022-03-19T07:50:49.710491Z","shell.execute_reply":"2022-03-19T07:54:37.344314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_acc = 0.0\ntest_lengths = 0\npred = np.array([], dtype=np.int32)\n\nmodel.load_state_dict(torch.load(\"../input/model-seed7/model.ckpt\", map_location='cpu'))\nmodel.eval()\nwith torch.no_grad():\n    for i, batch in enumerate(tqdm(test_loader)):\n        features = batch\n        features = features.permute(1, 0, 2).to(device)  # (seq_len, batch_size, feat_dim)\n        outputs = model(features)  # (seq_len, batch_size, cls_num)\n        _, test_pred = torch.max(outputs.permute(1, 0, 2), -1) # get the index of the class with the highest probability / (batch_size, seq_len)\n        pred = np.concatenate((pred, test_pred.squeeze().cpu().numpy()), axis=0)\n        \nwith open('prediction_model_seed7.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:54:37.347242Z","iopub.execute_input":"2022-03-19T07:54:37.347584Z","iopub.status.idle":"2022-03-19T07:58:26.5801Z","shell.execute_reply.started":"2022-03-19T07:54:37.347539Z","shell.execute_reply":"2022-03-19T07:58:26.57918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ensemble","metadata":{}},{"cell_type":"code","source":"def ensemble(model, pretrained_models):\n    probs = []\n    preds = []\n    for model_path in pretrained_models:\n        model.load_state_dict(torch.load(model_path, map_location='cpu'))\n        print(f'load model: {model_path}')\n        model.eval()\n        tmp_prob = []\n        tmp_pred = np.array([], dtype=np.int32)\n        with torch.no_grad():\n            for i, batch in enumerate(tqdm(test_loader)):\n                features = batch\n                features = features.permute(1, 0, 2).to(device)  # (seq_len, batch_size=1, feat_dim)\n                outputs = model(features)  # (seq_len, batch_size=1, cls_num)\n                tmp_prob.append(outputs.permute(1, 0, 2).cpu().numpy()[0])  # (batch_size=1, seq_len, cls_num)\n                \n                _, test_pred = torch.max(outputs.permute(1, 0, 2), -1) # get the index of the class with the highest probability / (batch_size=1, seq_len)\n                tmp_pred = np.concatenate((tmp_pred, test_pred.squeeze().cpu().numpy()), axis=0)\n            probs.append(np.concatenate(tmp_prob, axis=0))  # (tot_seq_len, cls_num)\n            preds.append(tmp_pred)  # (tot_seq_len, )\n    return probs, preds\n","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:43:19.588116Z","iopub.execute_input":"2022-03-19T07:43:19.588811Z","iopub.status.idle":"2022-03-19T07:43:19.600133Z","shell.execute_reply.started":"2022-03-19T07:43:19.588765Z","shell.execute_reply":"2022-03-19T07:43:19.599299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_pathes = ['../input/model-seed42/model.ckpt', '../input/model-seed7/model.ckpt'   \nprobs, preds = ensemble(model, model_pathes)","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:43:19.940988Z","iopub.execute_input":"2022-03-19T07:43:19.941322Z","iopub.status.idle":"2022-03-19T07:50:48.732498Z","shell.execute_reply.started":"2022-03-19T07:43:19.941285Z","shell.execute_reply":"2022-03-19T07:50:48.731387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### average logist","metadata":{}},{"cell_type":"code","source":"prob_out = np.zeros_like(probs[0])\nfor prob in probs:\n    prob_out += (1 / len(probs)) * prob\nprint(prob_out.shape)\n\npred_by_ensemble_probs = np.argmax(prob_out, axis=1).astype(np.int32)\nprint(pred_by_ensemble_probs.shape)\n\nwith open('prediction_ensemble_probs.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred_by_ensemble_probs):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T08:23:01.374435Z","iopub.execute_input":"2022-03-19T08:23:01.374987Z","iopub.status.idle":"2022-03-19T08:23:02.335602Z","shell.execute_reply.started":"2022-03-19T08:23:01.374951Z","shell.execute_reply":"2022-03-19T08:23:02.334589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### votting","metadata":{}},{"cell_type":"code","source":"pred_out = np.zeros_like(preds[0])\nfor i, prob in enumerate(zip(*preds)):\n    if np.random.rand() < 0.5:\n        pred_out[i] = prob[0]\n    else:\n        pred_out[i] = prob[1]\n    \nprint(pred_out.shape)\n\npred_by_ensemble_probs = np.max(prob_out, axis=1)\nprint(pred_by_ensemble_probs.shape)\n\nwith open('prediction_ensemble_preds.csv', 'w') as f:\n    f.write('Id,Class\\n')\n    for i, y in enumerate(pred_out):\n        f.write('{},{}\\n'.format(i, y))","metadata":{"execution":{"iopub.status.busy":"2022-03-19T07:29:16.807255Z","iopub.execute_input":"2022-03-19T07:29:16.807566Z","iopub.status.idle":"2022-03-19T07:29:17.7908Z","shell.execute_reply.started":"2022-03-19T07:29:16.807533Z","shell.execute_reply":"2022-03-19T07:29:17.789393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}